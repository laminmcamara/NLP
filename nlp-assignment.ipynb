{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5176304e-ac85-418b-af8e-55f3d8e81648",
   "metadata": {},
   "source": [
    "### NLP task : Take a text document\n",
    "#### a) Tokenize into sentences and words\n",
    "\n",
    "#### b) remove stop words and punctuation\n",
    "\n",
    "#### c) Lemmatize the words\n",
    "\n",
    "#### d) summarize the speech\n",
    "\n",
    "### Use Beautiful Soup to scrape a page on the internet - eg. Hong Kong Wikipedia Page\n",
    "\n",
    "### Create a summary of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ee81e27-6dc1-4a5e-af34-fafc8510ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the page.\n",
      "Length of text: 59685\n",
      "Retrieved text snippet:\n",
      "Contents \n",
      " Hong Kong[e] is a special administrative region of the People's Republic of China. With 7.4 million residents of various nationalities[f] in a 1,104-square-kilometre (426 sq mi) territory, Hong Kong is the fourth most densely populated region in the world.\n",
      " Hong Kong was established as a colony of the British Empire after the Qing dynasty ceded Hong Kong Island in 1841–1842 as a consequence of losing the First Opium War. The colony expanded to the Kowloon Peninsula in 1860 and was fur\n"
     ]
    }
   ],
   "source": [
    "# import libraries as required\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fetch the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/Hong_Kong\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check the response status\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully fetched the page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "# Parse the content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# We will try finding all relevant paragraphs and other content\n",
    "content = soup.find_all(['p', 'h2', 'h3'])  # Include headings for context\n",
    "\n",
    "# Check if content is found\n",
    "if content:\n",
    "    text = ' '.join([element.get_text() for element in content])\n",
    "else:\n",
    "    print(\"No content found in the expected div.\")\n",
    "\n",
    "# Print the length of the retrieved text\n",
    "print(f\"Length of text: {len(text)}\")\n",
    "\n",
    "# If text is empty, print part of the raw HTML for debugging\n",
    "if len(text) == 0:\n",
    "    print(\"Raw HTML snippet:\")\n",
    "    print(response.content[:1000])  # Print the first 1000 characters\n",
    "else:\n",
    "    print(\"Retrieved text snippet:\")\n",
    "    print(text[:500])  # Print the first 500 characters of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "670c351b-c810-4b89-a4c6-b0cd2d407078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing more libraries\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61536ed8-0fb7-4fb8-81fd-a27fda31ec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences:\n",
      "[\"Contents \\n Hong Kong[e] is a special administrative region of the People's Republic of China.\", 'With 7.4 million residents of various nationalities[f] in a 1,104-square-kilometre (426\\xa0sq\\xa0mi) territory, Hong Kong is the fourth most densely populated region in the world.', 'Hong Kong was established as a colony of the British Empire after the Qing dynasty ceded Hong Kong Island in 1841–1842 as a consequence of losing the First Opium War.']\n",
      "\n",
      "Filtered Words:\n",
      "['Contents', 'Hong', 'Kong', 'e', 'special', 'administrative', 'region', 'People', 'Republic', 'China']\n",
      "\n",
      "Lemmatized Words:\n",
      "['content', 'hong', 'kong', 'e', 'special', 'administrative', 'region', 'people', 'republic', 'china']\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "words = word_tokenize(text)\n",
    "\n",
    "#Remove Stop Words and Punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in filtered_words]\n",
    "\n",
    "# Print the results\n",
    "print(\"Tokenized Sentences:\")\n",
    "print(sentences[:3])  # Print first 3 sentences\n",
    "\n",
    "print(\"\\nFiltered Words:\")\n",
    "print(filtered_words[:10])  # Print first 10 filtered words\n",
    "\n",
    "print(\"\\nLemmatized Words:\")\n",
    "print(lemmatized_words[:10])  # Print first 10 lemmatized words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "830e9c68-1174-464c-8815-1385e8e64c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "[50] Administrative infrastructure was quickly built by early 1842, but piracy, disease, and hostile Qing policies initially prevented the government from attracting commerce.\n",
      "[65] Although the territory's competitiveness in manufacturing gradually declined because of rising labour and property costs, it transitioned to a service-based economy.\n",
      "[123] Hong Kong residents are not required to perform military service, and current law has no provision for local enlistment, so its defence is composed entirely of non-Hongkongers.\n",
      "[288] Vehicle traffic is extremely congested in urban areas, exacerbated by limited space to expand roads and an increasing number of vehicles.\n",
      "[324] Spiritual concepts such as feng shui are observed; large-scale construction projects often hire consultants to ensure proper building positioning and layout.\n"
     ]
    }
   ],
   "source": [
    "#Summarization\n",
    "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "summarizer = LsaSummarizer()\n",
    "summary = summarizer(parser.document, 5)  # Summarize to 5 sentences\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "for sentence in summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676cface-3092-475a-853e-9c97afd834ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
